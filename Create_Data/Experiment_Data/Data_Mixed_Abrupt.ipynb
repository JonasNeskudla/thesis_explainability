{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed - Abrupt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "#### Original definition of MIXED dataset \n",
    "- MIXED. Abrupt concept drift, boolean noise-free examples. Four relevant attributes, two boolean attributes v, w and two numeric attributes from [0, 1]. The examples are classiﬁed positive if two of three conditions are satisﬁed:v, w, y < 0.5 + 0.3 ∗ sin(3πx). After each context change the classiﬁcation is reversed.[1,2]\n",
    "\n",
    "To validate our approach we need drift in the data itself (virtual drift). For this purpose we have to modify the original data from the literature, but only as far as it is absolutely necessary. The original basic data distribution between the drifts, the selection of relevant features and the classifications function are adopted in general. \n",
    "But in this case we make an exception and do not change the classification function in case of a concept drift as it is described in literature to evaluate also an example where only virtual drift exists.\n",
    "\n",
    "#### Drifts, we have induced manually\n",
    "- Drift1:[5000:7500]: x and z with p now [0.0125,0.0125,0.0125,0.1,0.7,0.1,0.0125,0.0125,0.0125,0.0125,0.0125]\n",
    "- Drift2:[10000:12500]: x and z with p now [0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.1,0.7,0.1,0.0125,0.0125]\n",
    "- Drift3:[15000:17500]: x and z with p now [0.1,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.1,0.7]\n",
    "\n",
    "The classification function was - unlike in the paper - retained and was not reversed.\n",
    "\n",
    "\n",
    "#### Validation set\n",
    "We do not want to determine the optimal parameters for our approach on the same data set we are testing on. In this way we want to avoid \"overfitting\". For this reason we create a validation set. The data distribution of the validation set is created according to the same rules as the test set. Finally, a randomly selected drift from the test set is taken from the test set into the validation set to determine the parameters for our detector.\n",
    "- size of data set: 20000\n",
    "- train on 5%: 1000\n",
    "- validate on 10%: 2000\n",
    "- test on 85%: 17000\n",
    "\n",
    "The validation set and test set are containing the same 1000 instances for the initial training step.\n",
    "\n",
    "\n",
    "[1]: Gama, J., Medas, P., Castillo, G., & Rodrigues, P. (2004). Learning with drift detection. Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 3171(May 2014), 286–295. https://doi.org/10.1007/978-3-540-28645-5_29\n",
    "\n",
    "[2]: Kubat, M., & Widmer, G. (1995). Adapting to drift in continuous domains (Extended abstract). Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 912, 307–310. https://doi.org/10.1007/3-540-59286-5_74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "v = np.random.choice([False,True], size=20000)\n",
    "w = np.random.choice([False,True], size=20000)\n",
    "x = np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=[0.1,0.7,0.1,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125], size=20000)\n",
    "z = np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=[0.1,0.7,0.1,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125], size=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Drift 1\n",
    "x[5000:7500] = np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=[0.0125,0.0125,0.0125,0.1,0.7,0.1,0.0125,0.0125,0.0125,0.0125,0.0125], size=2500)\n",
    "z[5000:7500] = np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=[0.0125,0.0125,0.0125,0.1,0.7,0.1,0.0125,0.0125,0.0125,0.0125,0.0125], size=2500)\n",
    "\n",
    "#Drift 2\n",
    "x[10000:12500] = np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=[0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.1,0.7,0.1,0.0125,0.0125], size=2500)\n",
    "z[10000:12500] = np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=[0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.1,0.7,0.1,0.0125,0.0125], size=2500)\n",
    "\n",
    "#Drift 3\n",
    "x[15000:17500] = np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=[0.1,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.1,0.7], size=2500)\n",
    "z[15000:17500] = np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=[0.1,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.1,0.7], size=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "condition1 = v & w\n",
    "condition2 = v | w\n",
    "condition3 = z < 0.5 + 0.3 * np.sin(3*np.pi*x)\n",
    "\n",
    "y = np.where(condition1 | (condition2 & condition3),np.ones(20000, dtype=np.int8), np.zeros(20000, dtype=np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame([v,w,x,z,y]).transpose()\n",
    "data.columns = ['x1','x2','x3','x4', 'label']\n",
    "data['label'] = data['label'].astype('int32')\n",
    "\n",
    "# Encode x1 and x2\n",
    "le = preprocessing.LabelEncoder()\n",
    "data['x1'] = le.fit_transform(data['x1'])\n",
    "data['x2'] = le.fit_transform(data['x2'])\n",
    "\n",
    "df_train = data.iloc[:1000,:]\n",
    "df_test = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create validation set \n",
    "v = np.random.choice([False,True], size=2000)\n",
    "w = np.random.choice([False,True], size=2000)\n",
    "x = np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=[0.1,0.7,0.1,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125], size=2000)\n",
    "z = np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=[0.1,0.7,0.1,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125], size=2000)\n",
    "\n",
    "#Drift 1 (zuvor 2)\n",
    "x[500:1500] = np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=[0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.1,0.7,0.1,0.0125,0.0125], size=1000)\n",
    "z[500:1500] = np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=[0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.1,0.7,0.1,0.0125,0.0125], size=1000)\n",
    "condition1 = v & w\n",
    "condition2 = v | w\n",
    "condition3 = z < 0.5 + 0.3 * np.sin(3*np.pi*x)\n",
    "y = np.where(condition1 | (condition2 & condition3),np.ones(2000, dtype=np.int8), np.zeros(2000, dtype=np.int8))\n",
    "\n",
    "df_val = pd.DataFrame([v,w,x,z,y]).transpose() \n",
    "df_val.columns = ['x1','x2','x3','x4', 'label']\n",
    "df_val['label'] = df_val['label'].astype('int32')\n",
    "\n",
    "# Encode x1 and x2\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_val['x1'] = le.fit_transform(df_val['x1'])\n",
    "df_val['x2'] = le.fit_transform(df_val['x2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_and_validate = df_train.append(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_train_and_validate.to_csv('../../Experiment/Data_prep/own_synthetic/mixed_train_val.csv', index=False)\n",
    "df_test.to_csv('../../Experiment/Data_prep/own_synthetic/mixed_train_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

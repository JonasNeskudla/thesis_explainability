{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sine - Incremental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "#### Original definition of SINE dataset\n",
    "- SINE1: Abrupt concept drift, noise-free examples. The dataset has two relevant attributes. Each attribute has values uniformly distributed in [0, 1]. In the ﬁrst context all points below the curve y = sin(x) are classiﬁed as positive. After the context change the classiﬁcation is reversed. [1, 2]\n",
    "\n",
    "To validate our approach we need drift in the data itself (virtual drift). For this purpose we have to modify the original data from the literature, but only as far as it is absolutely necessary. The original basic data distribution between the drifts, the selection of relevant features and the classification function are adopted.\n",
    "\n",
    "#### Drifts, we have induced manually\n",
    "- Drift1[5000:15000]: shifting (0,1) to (0,11) by value 1 in steps of 1000 instances 10 times\n",
    "- Drift2[20000:25000]: shifting (0,1) to (0,-20) by value 2 in steps of 500 instances 10 times\n",
    "\n",
    "The classification function was - unlike with the same data set and abrupt drift - retained and was not reversed.\n",
    "\n",
    "#### Validation set\n",
    "We do not want to determine the optimal parameters for our approach on the same data set we are testing on. In this way we want to avoid \"overfitting\". For this reason we create a validation set. The data distribution of the validation set is created according to the same rules as the test set. Finally, a  modified version (opposite direction of shift, shorter drift width) of the second drift from the test set is taken from the test set to determine the parameters for our detector.\n",
    "- size of data set: 30000\n",
    "- train on 5%: 1500\n",
    "- validate on 10%: 3000\n",
    "- test on 85%: 25000\n",
    "\n",
    "The validation set and test set are containing the same 1500 instances for the initial training step.\n",
    "\n",
    "\n",
    "[1]: Gama, J., Medas, P., Castillo, G., & Rodrigues, P. (2004). Learning with drift detection. Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 3171(May 2014), 286–295. https://doi.org/10.1007/978-3-540-28645-5_29\n",
    "\n",
    "[2]: Kubat, M., & Widmer, G. (1995). Adapting to drift in continuous domains (Extended abstract). Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 912, 307–310. https://doi.org/10.1007/3-540-59286-5_74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "x1 = np.random.uniform(0,1,30000)\n",
    "x2 = np.random.uniform(0,1,30000)\n",
    "x3 = np.random.uniform(0,1,30000)\n",
    "x4 = np.random.uniform(0,1,30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-2 :    20000 : 20500\n",
      "-4 :    20500 : 21000\n",
      "-6 :    21000 : 21500\n",
      "-8 :    21500 : 22000\n",
      "-10 :    22000 : 22500\n",
      "-12 :    22500 : 23000\n",
      "-14 :    23000 : 23500\n",
      "-16 :    23500 : 24000\n",
      "-18 :    24000 : 24500\n",
      "-20 :    24500 : 25000\n"
     ]
    }
   ],
   "source": [
    "#Drift1 lang aber weniger stark\n",
    "j = 0\n",
    "for i in range(1,11):\n",
    "    #print(0,1+i, ':   ', 5000+j,':',6000+j)\n",
    "    x1[5000+j:6000+j]=np.random.uniform(0,1+i,1000)\n",
    "    x2[5000+j:6000+j]=np.random.uniform(0,1+i,1000)\n",
    "    j += 1000\n",
    "\n",
    "print()\n",
    "# stärkerer drift aber kürzer\n",
    "j=0\n",
    "for i in range(1,11):\n",
    "    print(0-(i*2), ':   ', 20000+j,':',20500+j)\n",
    "    x1[20000+j:20500+j]=np.random.uniform(0-(i*2),1,500)\n",
    "    x2[20000+j:20500+j]=np.random.uniform(0-(i*2),1,500)\n",
    "    j += 500\n",
    "    \n",
    "y= np.where(x2 > np.sin(x1), np.ones(30000, dtype=np.int8), np.zeros(30000, dtype=np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame([x1,x2,x3,x4,y]).transpose()\n",
    "data.columns = ['x1','x2','x3','x4', 'label']\n",
    "data['label'] = data['label'].astype('int32')\n",
    "\n",
    "df_train = data.iloc[:1500,:]\n",
    "df_test = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(50)\n",
    "\n",
    "\n",
    "# create validation set\n",
    "x1 = np.random.uniform(0,1,3000)\n",
    "x2 = np.random.uniform(0,1,3000)\n",
    "x3 = np.random.uniform(0,1,3000)\n",
    "x4 = np.random.uniform(0,1,3000)\n",
    "\n",
    "# stärkerer drift aber kürzer\n",
    "j=0\n",
    "for i in range(1,4):\n",
    "    #print(0,1+i*2, ':   ', 500+j,':',1000+j)\n",
    "    x1[500+j:1000+j]=np.random.uniform(0,1+i*2,500)\n",
    "    x2[500+j:1000+j]=np.random.uniform(0,1+i*2,500)\n",
    "    j += 500\n",
    "    \n",
    "y= np.where(x2 > np.sin(x1), np.ones(3000, dtype=np.int8), np.zeros(3000, dtype=np.int8))\n",
    "\n",
    "df_val = pd.DataFrame([x1,x2,x3,x4,y]).transpose()\n",
    "df_val.columns = ['x1','x2','x3','x4', 'label']\n",
    "df_val['label'] = df_val['label'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_and_validate = df_train.append(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_train_and_validate.to_csv('../../Experiment/Data_prep/own_synthetic/sine_incr_train_val.csv', index=False)\n",
    "df_test.to_csv('../../Experiment/Data_prep/own_synthetic/sine_incr_train_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

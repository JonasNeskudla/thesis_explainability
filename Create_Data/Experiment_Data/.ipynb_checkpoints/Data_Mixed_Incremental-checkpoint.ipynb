{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed - Incremental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "#### Original definition of MIXED dataset: \n",
    "- MIXED. Abrupt concept drift, boolean noise-free examples. Four relevant attributes, two boolean attributes v, w and two numeric attributes from [0, 1]. The examples are classiﬁed positive if two of three conditions are satisﬁed:v, w, y < 0.5 + 0.3 ∗ sin(3πx). After each context change the classiﬁcation is reversed.[1,2]\n",
    "\n",
    "To validate our approach we need drift in the data itself (virtual drift). For this purpose we have to modify the original data from the literature, but only as far as it is absolutely necessary. The original basic data distribution between the drifts, the selection of relevant features and the classifications function are adopted in general. \n",
    "But in this case we make an exception and do not change the classification function in case of a concept drift as it is described in literature to evaluate also an example where only virtual drift exists. Additionally, we induce incremental Drift, which is also not contained in the dataset originally.\n",
    "\n",
    "#### Incremental Drifts, we have induced manually:\n",
    "- Drift1:[5000:15000]: shifting p by 1 place in steps of 1000 instances 10 times\n",
    "- Drift2:[20000:25000]: shifting p by 2 places in steps of 500 instances 10 times\n",
    "\n",
    "The classification function was - unlike in the paper - retained and was not reversed.\n",
    "\n",
    "\n",
    "#### Validation set\n",
    "We do not want to determine the optimal parameters for our approach on the same data set we are testing on. In this way we want to avoid \"overfitting\". For this reason we create a validation set. The data distribution of the validation set is created according to the same rules as the test set. Finally, a  modified version (different initial p, shorter drift width) of the second drift from the test set is taken from the test set to determine the parameters for our detector.\n",
    "- size of data set: 30000\n",
    "- train on 5%: 1500\n",
    "- validate on 10%: 3000\n",
    "- test on 85%: 25000\n",
    "\n",
    "The validation set and test set are containing the same 1500 instances for the initial training step.\n",
    "\n",
    "\n",
    "[1]: Gama, J., Medas, P., Castillo, G., & Rodrigues, P. (2004). Learning with drift detection. Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 3171(May 2014), 286–295. https://doi.org/10.1007/978-3-540-28645-5_29\n",
    "\n",
    "[2]: Kubat, M., & Widmer, G. (1995). Adapting to drift in continuous domains (Extended abstract). Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 912, 307–310. https://doi.org/10.1007/3-540-59286-5_74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.random.choice([False,True], size=30000)\n",
    "w = np.random.choice([False,True], size=30000)\n",
    "x = np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=[0.1,0.7,0.1,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125], size=30000)\n",
    "z = np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=[0.1,0.7,0.1,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125], size=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Drift1 lang aber weniger stark\n",
    "j=0\n",
    "p=[0.1,0.7,0.1,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125]\n",
    "for i in range(10):\n",
    "    element = p.pop()\n",
    "    p.insert(0, element)\n",
    "    x[5000+j:6000+j]=np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=p, size=1000)\n",
    "    z[5000+j:6000+j]=np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=p, size=1000)\n",
    "    j += 1000\n",
    "\n",
    "print()\n",
    "# stärkerer drift aber kürzer\n",
    "j=0\n",
    "p=[0.1,0.7,0.1,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125]\n",
    "for i in range(10):\n",
    "    element = p[-2:]\n",
    "    del p[-2:]\n",
    "    p.insert(0, element[1])\n",
    "    p.insert(0, element[0])\n",
    "    \n",
    "    #print(20000+j,20500+j, p)\n",
    "    x[20000+j:20500+j]=np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=p, size=500)\n",
    "    z[20000+j:20500+j]=np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=p, size=500)\n",
    "    \n",
    "    j += 500\n",
    "    \n",
    "\n",
    "\n",
    "condition1 = v & w\n",
    "condition2 = v | w\n",
    "condition3 = z < 0.5 + 0.3 * np.sin(3*np.pi*x)\n",
    "\n",
    "y = np.where(condition1 | (condition2 & condition3),np.ones(30000, dtype=np.int8), np.zeros(30000, dtype=np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([v,w,x,z,y]).transpose()\n",
    "data.columns = ['x1','x2','x3','x4', 'label']\n",
    "data['label'] = data['label'].astype('int32')\n",
    "\n",
    "# Encode x1 and x2\n",
    "le = preprocessing.LabelEncoder()\n",
    "data['x1'] = le.fit_transform(data['x1'])\n",
    "data['x2'] = le.fit_transform(data['x2'])\n",
    "\n",
    "df_train = data.iloc[:1500,:]\n",
    "df_test = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create validation set\n",
    "v = np.random.choice([False,True], size=3000)\n",
    "w = np.random.choice([False,True], size=3000)\n",
    "x = np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=[0.1,0.7,0.1,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125], size=3000)\n",
    "z = np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=[0.1,0.7,0.1,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125], size=3000)\n",
    "\n",
    "# stärkerer drift aber kürzer\n",
    "j=0\n",
    "p=[0.0125,0.0125,0.1,0.7,0.1,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125]#starts with different p as it does in test set an is also shorter\n",
    "for i in range(3):\n",
    "    element = p[-2:]\n",
    "    del p[-2:]\n",
    "    p.insert(0, element[1])\n",
    "    p.insert(0, element[0])\n",
    "    #print(p)\n",
    "    #print(500+j, 1000+j)\n",
    "    x[500+j:1000+j]=np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=p, size=500)\n",
    "    z[500+j:1000+j]=np.random.choice([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], p=p, size=500)\n",
    "    j += 500\n",
    "    \n",
    "condition1 = v & w\n",
    "condition2 = v | w\n",
    "condition3 = z < 0.5 + 0.3 * np.sin(3*np.pi*x)\n",
    "\n",
    "y = np.where(condition1 | (condition2 & condition3),np.ones(3000, dtype=np.int8), np.zeros(3000, dtype=np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.DataFrame([v,w,x,z,y]).transpose()\n",
    "df_val.columns = ['x1','x2','x3','x4', 'label']\n",
    "df_val['label'] = df_val['label'].astype('int32')\n",
    "\n",
    "# Encode x1 and x2\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_val['x1'] = le.fit_transform(df_val['x1'])\n",
    "df_val['x2'] = le.fit_transform(df_val['x2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_and_validate = df_train.append(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.491778</td>\n",
       "      <td>0.505333</td>\n",
       "      <td>0.591333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.500027</td>\n",
       "      <td>0.491642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                x1           x2        label\n",
       "count  4500.000000  4500.000000  4500.000000\n",
       "mean      0.491778     0.505333     0.591333\n",
       "std       0.499988     0.500027     0.491642\n",
       "min       0.000000     0.000000     0.000000\n",
       "25%       0.000000     0.000000     0.000000\n",
       "50%       0.000000     1.000000     1.000000\n",
       "75%       1.000000     1.000000     1.000000\n",
       "max       1.000000     1.000000     1.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_and_validate.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.502300</td>\n",
       "      <td>0.498933</td>\n",
       "      <td>0.585533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500003</td>\n",
       "      <td>0.500007</td>\n",
       "      <td>0.492638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x1            x2         label\n",
       "count  30000.000000  30000.000000  30000.000000\n",
       "mean       0.502300      0.498933      0.585533\n",
       "std        0.500003      0.500007      0.492638\n",
       "min        0.000000      0.000000      0.000000\n",
       "25%        0.000000      0.000000      0.000000\n",
       "50%        1.000000      0.000000      1.000000\n",
       "75%        1.000000      1.000000      1.000000\n",
       "max        1.000000      1.000000      1.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_and_validate.to_csv('../../Experiment/Data_prep/own_synthetic/mixed_incr_train_val.csv', index=False)\n",
    "df_test.to_csv('../../Experiment/Data_prep/own_synthetic/mixed_incr_train_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
